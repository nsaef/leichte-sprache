# ML Flow Config
report_to: "mlflow"
run_name: "RUN_NAME"

# model params
model_name_or_path: "path/to/merged/model/"
output_dir: "output/path"

# dataset
dataset_name: "repo/dpo_dataset_name"

# general params
do_train: True
seed: 100
num_train_epochs: 4
logging_steps: 1
log_level: "info"
logging_strategy: "steps"
eval_strategy: "steps"
save_strategy: "steps"
eval_steps: 20
save_steps: 20

# training params
learning_rate: 0.00001
lr_scheduler_type: "cosine"
weight_decay: 0.0001
warmup_ratio: 0.0
max_grad_norm: 1.0
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 5
gradient_checkpointing: True

# Training Optimization
bf16: True
use_peft: True
lora_r: 8
lora_alpha: 16
lora_dropout: 0.1
lora_target_modules: "q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj"
