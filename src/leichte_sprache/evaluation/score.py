from statistics import mean

import evaluate
from lingua import Language, LanguageDetectorBuilder


def calculate_rouge(predictions: list[str], references: list[str]) -> list[float]:
    """Calculate rouge2 between two lists of texts.

    :param predictions: list of predicted texts
    :param references: list of reference texts
    :return: list of rouge2 scores
    """
    rouge = evaluate.load("rouge")
    scores = rouge.compute(
        predictions=predictions,
        references=references,
        rouge_types=["rouge2"],
        use_aggregator=False,
    )
    return scores["rouge2"]


def recognize_language(texts: list[str]) -> list[str]:
    """Run automated language recognition on a list of texts, such as  `GERMAN` or `ENGLISH`.

    :param texts: list of texts
    :return: list of language names
    """
    languages = [Language.ENGLISH, Language.GERMAN]
    detector = LanguageDetectorBuilder.from_languages(*languages).build()
    langs = detector.detect_languages_in_parallel_of(texts)
    lang_strings = [l.name if l else None for l in langs]
    return lang_strings


def split_text_naive(
    text: str, sep: str = None, separate_hyphens: bool = True
) -> list[str]:
    """Naive word splitting. Splits the text at the given separator and returns a list of words.
    Defaults to splitting at whitespace. By default, also replaces hyphens (which are commonly
    inserted into long words in Leichte Sprache) with the separator to account for the added
    readibility generated by this spelling.

    :param text: input string
    :param sep: separator. Default: None
    :param separate_hyphens: replace hyphens with the separator token to count hyphenated words as multiple words. Default:True
    :return: list of words
    """
    if separate_hyphens:
        replacement = " " if sep is None else sep
        text = text.replace("-", replacement)
    split = text.split(sep)
    return split


def calc_mean_word_length(split_text: list[str]) -> float:
    """Calculate the mean word length of a split (tokenized) text.
    Split the text using `score.split_text_naive` with your preferred
    parameters before using this function.

    :param split_text: text split into words
    :return: mean word length across the whole text
    """
    result = mean([len(w) for w in split_text])
    return result


def score_classification_set():
    # get the dataset
    # run readibility, lexical diversity, avg sentence length, avg word length, avg text length?
    # -> sentence length and word length SHOULD be comprised in readibility
    # -> text length would be biased a lot by the very short dictionary entries
    pass


if __name__ == "__main__":
    score_classification_set()
